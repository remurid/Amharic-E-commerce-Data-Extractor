{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf338962",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"./final_amharic_ner_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "def predict(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    logits = output.logits[0]\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    return probs.numpy(), tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc74d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = list(model.config.id2label.values())\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "def lime_wrapper(texts):\n",
    "    probs, tokens = predict(texts[0])\n",
    "    # Get the most confident tag per token\n",
    "    token_probs = np.max(probs, axis=-1)\n",
    "    return token_probs.reshape(1, -1)\n",
    "\n",
    "# Pick a sample text\n",
    "sample_text = \"አማርኛ ሱቅ በአዲስ አበባ ነው\"\n",
    "\n",
    "# Run LIME\n",
    "exp = explainer.explain_instance(sample_text, lime_wrapper, num_features=10)\n",
    "\n",
    "# Visualize\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d084a8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def shap_wrapper(texts):\n",
    "    probs, tokens = predict(texts[0])\n",
    "    return np.max(probs, axis=-1)\n",
    "\n",
    "explainer = shap.Explainer(shap_wrapper, tokenizer)\n",
    "shap_values = explainer([sample_text])\n",
    "\n",
    "shap.plots.text(shap_values[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
